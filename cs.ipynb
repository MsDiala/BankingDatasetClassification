{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8p/b3ws2sh942n4mms732sp99fr0000gn/T/ipykernel_28061/1199048596.py:27: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  all_data['day'] = pd.to_datetime(all_data['day'])\n",
      "/var/folders/8p/b3ws2sh942n4mms732sp99fr0000gn/T/ipykernel_28061/1199048596.py:36: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  all_data['day'] = pd.to_datetime(all_data['day'], errors='coerce')\n",
      "/Users/macbookpro/Library/Python/3.9/lib/python/site-packages/sklearn/impute/_base.py:555: UserWarning: Skipping features without any observed values: ['day_of_week']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (78161, 1), indices imply (78161, 71)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m all_columns \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(numeric_cols) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(encoded_columns)\n\u001b[1;32m     68\u001b[0m \u001b[39m# Convert the preprocessed data array to a DataFrame with proper column names\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m cleaned_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(X_all_preprocessed, columns\u001b[39m=\u001b[39;49mall_columns)\n\u001b[1;32m     71\u001b[0m \u001b[39m# Save the preprocessed and feature-engineered data to a CSV file\u001b[39;00m\n\u001b[1;32m     72\u001b[0m cleaned_data\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mcleaned_data.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:798\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    790\u001b[0m         mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    791\u001b[0m             arrays,\n\u001b[1;32m    792\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    797\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    799\u001b[0m             data,\n\u001b[1;32m    800\u001b[0m             index,\n\u001b[1;32m    801\u001b[0m             columns,\n\u001b[1;32m    802\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    803\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    804\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    805\u001b[0m         )\n\u001b[1;32m    806\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    808\u001b[0m         {},\n\u001b[1;32m    809\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    813\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/construction.py:337\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    333\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    334\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    335\u001b[0m )\n\u001b[0;32m--> 337\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    340\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/construction.py:408\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    406\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    407\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 408\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (78161, 1), indices imply (78161, 71)"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load the training and test data\n",
    "train_data = pd.read_csv('Train-set.csv')\n",
    "test_data = pd.read_csv('Test-set.csv')\n",
    "\n",
    "# Separate the 'Target' column (labels) from the training data\n",
    "y_train = train_data['Target']\n",
    "train_data.drop('Target', axis=1, inplace=True)\n",
    "\n",
    "# Combine train and test data for preprocessing\n",
    "all_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "# Feature Engineering: Extract day of the week and create a weekend indicator\n",
    "try:\n",
    "    # Convert 'day' column to datetime\n",
    "    all_data['day'] = pd.to_datetime(all_data['day'])\n",
    "    # Extract day of the week (0-6) and create 'day_of_week' feature\n",
    "    all_data['day_of_week'] = all_data['day'].dt.dayofweek\n",
    "    # Create binary indicator for weekend (Saturday and Sunday)\n",
    "    all_data['is_weekend'] = all_data['day_of_week'].isin([5, 6]).astype(int)\n",
    "    # Drop the original 'day' column\n",
    "    all_data.drop('day', axis=1, inplace=True)\n",
    "except (ValueError, OverflowError, pd._libs.tslibs.np_datetime.OutOfBoundsDatetime):\n",
    "    # Handle errors due to invalid date formats\n",
    "    all_data['day'] = pd.to_datetime(all_data['day'], errors='coerce')\n",
    "    all_data['day_of_week'] = all_data['day'].dt.dayofweek\n",
    "    all_data['is_weekend'] = all_data['day_of_week'].isin([5, 6]).astype(int)\n",
    "    all_data.drop('day', axis=1, inplace=True)\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = all_data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = all_data.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Create transformers for numeric and categorical columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocess the data using the column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "X_all_preprocessed = preprocessor.fit_transform(all_data)\n",
    "\n",
    "# Get the names of the columns after one-hot encoding\n",
    "encoded_columns = preprocessor.named_transformers_['cat'].named_steps['encoder'].get_feature_names_out(categorical_cols)\n",
    "all_columns = list(numeric_cols) + list(encoded_columns)\n",
    "\n",
    "# Convert the preprocessed data array to a DataFrame with proper column names\n",
    "cleaned_data = pd.DataFrame(X_all_preprocessed, columns=all_columns)\n",
    "\n",
    "# Save the preprocessed and feature-engineered data to a CSV file\n",
    "cleaned_data.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "# Handle class imbalance using BorderlineSMOTE\n",
    "smote = BorderlineSMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_all_preprocessed[:train_data.shape[0]], y_train)\n",
    "\n",
    "# Create and train optimized models\n",
    "optimized_rf_model = RandomForestClassifier(n_estimators=150, max_depth=9, random_state=42)\n",
    "optimized_rf_model.fit(X_train_resampled, y_train_resampled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
