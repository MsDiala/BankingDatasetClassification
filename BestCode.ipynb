{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8p/b3ws2sh942n4mms732sp99fr0000gn/T/ipykernel_28322/4211528759.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  all_data['day'] = pd.to_datetime(all_data['day'])\n",
      "/var/folders/8p/b3ws2sh942n4mms732sp99fr0000gn/T/ipykernel_28322/4211528759.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  all_data['day'] = pd.to_datetime(all_data['day'], errors='coerce')\n",
      "/Users/macbookpro/Library/Python/3.9/lib/python/site-packages/sklearn/impute/_base.py:555: UserWarning: Skipping features without any observed values: ['day_of_week']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 48433, number of negative: 48433\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16946\n",
      "[LightGBM] [Info] Number of data points in the train set: 96866, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "# Banking Dataset Classification\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd  # Importing pandas library for data manipulation and analysis\n",
    "import numpy as np  # Importing numpy library for numerical operations\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV  # Importing functions for data splitting and hyperparameter tuning\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder  # Importing preprocessing tools for scaling and one-hot encoding\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  # Importing ensemble classifiers\n",
    "from lightgbm import LGBMClassifier  # Importing LightGBM classifier\n",
    "from sklearn.impute import SimpleImputer  # Importing SimpleImputer for handling missing data\n",
    "from sklearn.compose import ColumnTransformer  # Importing ColumnTransformer for column-wise transformations\n",
    "from sklearn.pipeline import Pipeline  # Importing Pipeline for creating a processing pipeline\n",
    "from sklearn.metrics import accuracy_score  # Importing accuracy_score for model evaluation\n",
    "from imblearn.over_sampling import BorderlineSMOTE  # Importing BorderlineSMOTE for handling class imbalance\n",
    "import os  # Importing operating system utilities for file handling\n",
    "\n",
    "# Load the training and test data\n",
    "train_data = pd.read_csv('Train-set.csv')  # Load the training data from a CSV file\n",
    "test_data = pd.read_csv('Test-set.csv')    # Load the test data from a CSV file\n",
    "\n",
    "# Separate the 'Target' column from the train data\n",
    "y_train = train_data['Target']  # Storing the target labels in 'y_train'\n",
    "train_data.drop('Target', axis=1, inplace=True)  # Removing the target column from the training data\n",
    "\n",
    "# Combine train and test data for preprocessing\n",
    "all_data = pd.concat([train_data, test_data], axis=0)  # Combining train and test data for combined preprocessing\n",
    "\n",
    "# Feature Engineering: Extract day of the week and create a weekend indicator\n",
    "try:\n",
    "    # Convert 'day' column to datetime\n",
    "    all_data['day'] = pd.to_datetime(all_data['day'])\n",
    "    # Extract day of the week (0-6) and create 'day_of_week' feature\n",
    "    all_data['day_of_week'] = all_data['day'].dt.dayofweek\n",
    "    # Create binary indicator for the weekend (Saturday and Sunday)\n",
    "    all_data['is_weekend'] = all_data['day_of_week'].isin([5, 6]).astype(int)\n",
    "    # Drop the original 'day' column\n",
    "    all_data.drop('day', axis=1, inplace=True)\n",
    "except (ValueError, OverflowError, pd._libs.tslibs.np_datetime.OutOfBoundsDatetime):\n",
    "    # Handle errors due to invalid date formats\n",
    "    all_data['day'] = pd.to_datetime(all_data['day'], errors='coerce')\n",
    "    all_data['day_of_week'] = all_data['day'].dt.dayofweek\n",
    "    all_data['is_weekend'] = all_data['day_of_week'].isin([5, 6]).astype(int)\n",
    "    all_data.drop('day', axis=1, inplace=True)\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = all_data.select_dtypes(include=[np.number]).columns  # Identifying numeric columns\n",
    "categorical_cols = all_data.select_dtypes(include=[object]).columns  # Identifying categorical columns\n",
    "\n",
    "# Create transformers for numeric and categorical columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Impute missing values with median\n",
    "    ('scaler', RobustScaler())  # Scale features using robust scaling\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with the most frequent value\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # Encode categorical variables using one-hot encoding\n",
    "])\n",
    "\n",
    "# Preprocess the data using the column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),  # Apply numeric transformer to numeric columns\n",
    "    ('cat', categorical_transformer, categorical_cols)  # Apply categorical transformer to categorical columns\n",
    "])\n",
    "\n",
    "X_all_preprocessed = preprocessor.fit_transform(all_data)  # Apply preprocessing to all data\n",
    "\n",
    "# Handle class imbalance using BorderlineSMOTE\n",
    "smote = BorderlineSMOTE(sampling_strategy='auto', random_state=42)  # Initialize BorderlineSMOTE for oversampling\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_all_preprocessed[:train_data.shape[0]], y_train)\n",
    "# Apply BorderlineSMOTE to balance classes in the training data\n",
    "\n",
    "# Create and train optimized models\n",
    "optimized_rf_model = RandomForestClassifier(n_estimators=150, max_depth=9, random_state=42)\n",
    "# Initialize RandomForestClassifier with optimized hyperparameters\n",
    "optimized_gb_model = GradientBoostingClassifier(n_estimators=160, learning_rate=0.05, max_depth=7, random_state=42)\n",
    "# Initialize GradientBoostingClassifier with optimized hyperparameters\n",
    "optimized_lgbm_model = LGBMClassifier(n_estimators=180, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "# Initialize LGBMClassifier with optimized hyperparameters\n",
    "\n",
    "optimized_rf_model.fit(X_train_resampled, y_train_resampled)  # Train RandomForestClassifier on resampled data\n",
    "optimized_gb_model.fit(X_train_resampled, y_train_resampled)  # Train GradientBoostingClassifier on resampled data\n",
    "optimized_lgbm_model.fit(X_train_resampled, y_train_resampled)  # Train LGBMClassifier on resampled data\n",
    "\n",
    "# Get predictions using optimized models\n",
    "test_predictions_rf = optimized_rf_model.predict_proba(X_all_preprocessed[train_data.shape[0]:])[:, 1]\n",
    "# Predict probabilities for class 1 using RandomForestClassifier\n",
    "test_predictions_gb = optimized_gb_model.predict_proba(X_all_preprocessed[train_data.shape[0]:])[:, 1]\n",
    "# Predict probabilities for class 1 using GradientBoostingClassifier\n",
    "test_predictions_lgbm = optimized_lgbm_model.predict_proba(X_all_preprocessed[train_data.shape[0]:])[:, 1]\n",
    "# Predict probabilities for class 1 using LGBMClassifier\n",
    "\n",
    "# Combine the predictions using weighted averaging\n",
    "ensemble_predictions = (0.4 * test_predictions_rf) + (0.4 * test_predictions_gb) + (0.2 * test_predictions_lgbm)\n",
    "# Weighted average of predictions from all three models\n",
    "threshold = 0.5  # Set the threshold for converting probabilities to binary predictions\n",
    "binary_predictions = (ensemble_predictions >= threshold).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Get the 'id' values from the test_data DataFrame\n",
    "submission_ids = test_data['id']\n",
    "\n",
    "# Create binary predictions based on a threshold (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "binary_predictions = (ensemble_predictions >= threshold).astype(int)\n",
    "\n",
    "# Create the submission DataFrame with 'id' and binary 'Target' values\n",
    "submission_df = pd.DataFrame({'id': submission_ids, 'Target': binary_predictions})\n",
    "\n",
    "# Save the submission file to CSV\n",
    "submission_df.to_csv('submission_binary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (78161, 1), indices imply (78161, 71)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m all_columns \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(numeric_cols) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(encoded_cols)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Convert the preprocessed data array to a DataFrame with proper column names\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m preprocessed_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(X_all_preprocessed, columns\u001b[39m=\u001b[39;49mall_columns)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Save the preprocessed and feature-engineered data to a CSV file\u001b[39;00m\n\u001b[1;32m     11\u001b[0m preprocessed_data\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mpreprocessed_data.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:798\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    790\u001b[0m         mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    791\u001b[0m             arrays,\n\u001b[1;32m    792\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    797\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    799\u001b[0m             data,\n\u001b[1;32m    800\u001b[0m             index,\n\u001b[1;32m    801\u001b[0m             columns,\n\u001b[1;32m    802\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    803\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    804\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    805\u001b[0m         )\n\u001b[1;32m    806\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    808\u001b[0m         {},\n\u001b[1;32m    809\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    813\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/construction.py:337\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    333\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    334\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    335\u001b[0m )\n\u001b[0;32m--> 337\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    340\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/construction.py:408\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    406\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    407\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 408\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (78161, 1), indices imply (78161, 71)"
     ]
    }
   ],
   "source": [
    "# Define the column names for the preprocessed data\n",
    "numeric_cols = all_data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = all_data.select_dtypes(include=[object]).columns\n",
    "encoded_cols = preprocessor.named_transformers_['cat'].named_steps['encoder'].get_feature_names_out(categorical_cols)\n",
    "all_columns = list(numeric_cols) + list(encoded_cols)\n",
    "\n",
    "# Convert the preprocessed data array to a DataFrame with proper column names\n",
    "preprocessed_data = pd.DataFrame(X_all_preprocessed, columns=all_columns)\n",
    "\n",
    "# Save the preprocessed and feature-engineered data to a CSV file\n",
    "preprocessed_data.to_csv('preprocessed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
